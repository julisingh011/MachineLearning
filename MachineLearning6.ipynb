{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b73614-ef93-44f0-8a54-4ca5e9a85a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "x,y=make_regression(n_samples=1000,n_features=30,noise=10,random_state=42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e6536e-facd-4fe6-9927-c04585dbbe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   8169.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 13 Nov 2025</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:26:27</td>     <th>  Log-Likelihood:    </th>          <td> -3000.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th>          <td>   6060.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   770</td>      <th>  BIC:               </th>          <td>   6201.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    30</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.0819</td> <td>    0.364</td> <td>    0.225</td> <td> 0.822</td> <td>   -0.632</td> <td>    0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>    0.2207</td> <td>    0.379</td> <td>    0.582</td> <td> 0.560</td> <td>   -0.523</td> <td>    0.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.0259</td> <td>    0.373</td> <td>    0.069</td> <td> 0.945</td> <td>   -0.707</td> <td>    0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -0.4613</td> <td>    0.394</td> <td>   -1.171</td> <td> 0.242</td> <td>   -1.235</td> <td>    0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>    0.0293</td> <td>    0.377</td> <td>    0.078</td> <td> 0.938</td> <td>   -0.710</td> <td>    0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   43.0693</td> <td>    0.389</td> <td>  110.778</td> <td> 0.000</td> <td>   42.306</td> <td>   43.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>   -0.2630</td> <td>    0.385</td> <td>   -0.683</td> <td> 0.495</td> <td>   -1.019</td> <td>    0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -0.5716</td> <td>    0.364</td> <td>   -1.569</td> <td> 0.117</td> <td>   -1.287</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>   -0.0258</td> <td>    0.370</td> <td>   -0.070</td> <td> 0.945</td> <td>   -0.753</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   -0.1187</td> <td>    0.367</td> <td>   -0.323</td> <td> 0.747</td> <td>   -0.840</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>    0.6126</td> <td>    0.384</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.141</td> <td>    1.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>   61.4623</td> <td>    0.383</td> <td>  160.297</td> <td> 0.000</td> <td>   60.710</td> <td>   62.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   39.7185</td> <td>    0.388</td> <td>  102.363</td> <td> 0.000</td> <td>   38.957</td> <td>   40.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>    0.4573</td> <td>    0.363</td> <td>    1.260</td> <td> 0.208</td> <td>   -0.255</td> <td>    1.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>   -0.2084</td> <td>    0.374</td> <td>   -0.557</td> <td> 0.578</td> <td>   -0.943</td> <td>    0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>   38.1697</td> <td>    0.384</td> <td>   99.461</td> <td> 0.000</td> <td>   37.416</td> <td>   38.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>   -0.0796</td> <td>    0.394</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.853</td> <td>    0.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td>    0.6095</td> <td>    0.373</td> <td>    1.633</td> <td> 0.103</td> <td>   -0.123</td> <td>    1.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>   82.6706</td> <td>    0.370</td> <td>  223.690</td> <td> 0.000</td> <td>   81.945</td> <td>   83.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>   -0.5558</td> <td>    0.382</td> <td>   -1.454</td> <td> 0.146</td> <td>   -1.306</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>   69.3788</td> <td>    0.382</td> <td>  181.451</td> <td> 0.000</td> <td>   68.628</td> <td>   70.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>   -0.2760</td> <td>    0.376</td> <td>   -0.734</td> <td> 0.463</td> <td>   -1.014</td> <td>    0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th> <td>   78.4182</td> <td>    0.385</td> <td>  203.868</td> <td> 0.000</td> <td>   77.663</td> <td>   79.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th> <td>   -0.0071</td> <td>    0.381</td> <td>   -0.019</td> <td> 0.985</td> <td>   -0.755</td> <td>    0.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th> <td>   -0.4508</td> <td>    0.378</td> <td>   -1.191</td> <td> 0.234</td> <td>   -1.194</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th> <td>    0.0881</td> <td>    0.377</td> <td>    0.234</td> <td> 0.815</td> <td>   -0.651</td> <td>    0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th> <td>    5.7140</td> <td>    0.376</td> <td>   15.199</td> <td> 0.000</td> <td>    4.976</td> <td>    6.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th> <td>   88.5939</td> <td>    0.381</td> <td>  232.561</td> <td> 0.000</td> <td>   87.846</td> <td>   89.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th> <td>   17.3467</td> <td>    0.396</td> <td>   43.790</td> <td> 0.000</td> <td>   16.569</td> <td>   18.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th> <td>   -0.6469</td> <td>    0.375</td> <td>   -1.726</td> <td> 0.085</td> <td>   -1.383</td> <td>    0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.178</td> <th>  Durbin-Watson:     </th> <td>   1.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.204</td> <th>  Jarque-Bera (JB):  </th> <td>   3.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.014</td> <th>  Prob(JB):          </th> <td>   0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.325</td> <th>  Cond. No.          </th> <td>    1.43</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared (uncentered):}      &     0.997   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.997   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     8169.   \\\\\n",
       "\\textbf{Date:}             & Thu, 13 Nov 2025 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}             &     22:26:27     & \\textbf{  Log-Likelihood:    }          &   -3000.1   \\\\\n",
       "\\textbf{No. Observations:} &         800      & \\textbf{  AIC:               }          &     6060.   \\\\\n",
       "\\textbf{Df Residuals:}     &         770      & \\textbf{  BIC:               }          &     6201.   \\\\\n",
       "\\textbf{Df Model:}         &          30      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{x1}  &       0.0819  &        0.364     &     0.225  &         0.822        &       -0.632    &        0.796     \\\\\n",
       "\\textbf{x2}  &       0.2207  &        0.379     &     0.582  &         0.560        &       -0.523    &        0.965     \\\\\n",
       "\\textbf{x3}  &       0.0259  &        0.373     &     0.069  &         0.945        &       -0.707    &        0.759     \\\\\n",
       "\\textbf{x4}  &      -0.4613  &        0.394     &    -1.171  &         0.242        &       -1.235    &        0.312     \\\\\n",
       "\\textbf{x5}  &       0.0293  &        0.377     &     0.078  &         0.938        &       -0.710    &        0.769     \\\\\n",
       "\\textbf{x6}  &      43.0693  &        0.389     &   110.778  &         0.000        &       42.306    &       43.833     \\\\\n",
       "\\textbf{x7}  &      -0.2630  &        0.385     &    -0.683  &         0.495        &       -1.019    &        0.493     \\\\\n",
       "\\textbf{x8}  &      -0.5716  &        0.364     &    -1.569  &         0.117        &       -1.287    &        0.144     \\\\\n",
       "\\textbf{x9}  &      -0.0258  &        0.370     &    -0.070  &         0.945        &       -0.753    &        0.701     \\\\\n",
       "\\textbf{x10} &      -0.1187  &        0.367     &    -0.323  &         0.747        &       -0.840    &        0.602     \\\\\n",
       "\\textbf{x11} &       0.6126  &        0.384     &     1.595  &         0.111        &       -0.141    &        1.367     \\\\\n",
       "\\textbf{x12} &      61.4623  &        0.383     &   160.297  &         0.000        &       60.710    &       62.215     \\\\\n",
       "\\textbf{x13} &      39.7185  &        0.388     &   102.363  &         0.000        &       38.957    &       40.480     \\\\\n",
       "\\textbf{x14} &       0.4573  &        0.363     &     1.260  &         0.208        &       -0.255    &        1.170     \\\\\n",
       "\\textbf{x15} &      -0.2084  &        0.374     &    -0.557  &         0.578        &       -0.943    &        0.526     \\\\\n",
       "\\textbf{x16} &      38.1697  &        0.384     &    99.461  &         0.000        &       37.416    &       38.923     \\\\\n",
       "\\textbf{x17} &      -0.0796  &        0.394     &    -0.202  &         0.840        &       -0.853    &        0.694     \\\\\n",
       "\\textbf{x18} &       0.6095  &        0.373     &     1.633  &         0.103        &       -0.123    &        1.342     \\\\\n",
       "\\textbf{x19} &      82.6706  &        0.370     &   223.690  &         0.000        &       81.945    &       83.396     \\\\\n",
       "\\textbf{x20} &      -0.5558  &        0.382     &    -1.454  &         0.146        &       -1.306    &        0.194     \\\\\n",
       "\\textbf{x21} &      69.3788  &        0.382     &   181.451  &         0.000        &       68.628    &       70.129     \\\\\n",
       "\\textbf{x22} &      -0.2760  &        0.376     &    -0.734  &         0.463        &       -1.014    &        0.463     \\\\\n",
       "\\textbf{x23} &      78.4182  &        0.385     &   203.868  &         0.000        &       77.663    &       79.173     \\\\\n",
       "\\textbf{x24} &      -0.0071  &        0.381     &    -0.019  &         0.985        &       -0.755    &        0.740     \\\\\n",
       "\\textbf{x25} &      -0.4508  &        0.378     &    -1.191  &         0.234        &       -1.194    &        0.292     \\\\\n",
       "\\textbf{x26} &       0.0881  &        0.377     &     0.234  &         0.815        &       -0.651    &        0.827     \\\\\n",
       "\\textbf{x27} &       5.7140  &        0.376     &    15.199  &         0.000        &        4.976    &        6.452     \\\\\n",
       "\\textbf{x28} &      88.5939  &        0.381     &   232.561  &         0.000        &       87.846    &       89.342     \\\\\n",
       "\\textbf{x29} &      17.3467  &        0.396     &    43.790  &         0.000        &       16.569    &       18.124     \\\\\n",
       "\\textbf{x30} &      -0.6469  &        0.375     &    -1.726  &         0.085        &       -1.383    &        0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.178 & \\textbf{  Durbin-Watson:     } &    1.949  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.204 & \\textbf{  Jarque-Bera (JB):  } &    3.556  \\\\\n",
       "\\textbf{Skew:}          &  0.014 & \\textbf{  Prob(JB):          } &    0.169  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.325 & \\textbf{  Cond. No.          } &     1.43  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.997\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.997\n",
       "Method:                 Least Squares   F-statistic:                              8169.\n",
       "Date:                Thu, 13 Nov 2025   Prob (F-statistic):                        0.00\n",
       "Time:                        22:26:27   Log-Likelihood:                         -3000.1\n",
       "No. Observations:                 800   AIC:                                      6060.\n",
       "Df Residuals:                     770   BIC:                                      6201.\n",
       "Df Model:                          30                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0819      0.364      0.225      0.822      -0.632       0.796\n",
       "x2             0.2207      0.379      0.582      0.560      -0.523       0.965\n",
       "x3             0.0259      0.373      0.069      0.945      -0.707       0.759\n",
       "x4            -0.4613      0.394     -1.171      0.242      -1.235       0.312\n",
       "x5             0.0293      0.377      0.078      0.938      -0.710       0.769\n",
       "x6            43.0693      0.389    110.778      0.000      42.306      43.833\n",
       "x7            -0.2630      0.385     -0.683      0.495      -1.019       0.493\n",
       "x8            -0.5716      0.364     -1.569      0.117      -1.287       0.144\n",
       "x9            -0.0258      0.370     -0.070      0.945      -0.753       0.701\n",
       "x10           -0.1187      0.367     -0.323      0.747      -0.840       0.602\n",
       "x11            0.6126      0.384      1.595      0.111      -0.141       1.367\n",
       "x12           61.4623      0.383    160.297      0.000      60.710      62.215\n",
       "x13           39.7185      0.388    102.363      0.000      38.957      40.480\n",
       "x14            0.4573      0.363      1.260      0.208      -0.255       1.170\n",
       "x15           -0.2084      0.374     -0.557      0.578      -0.943       0.526\n",
       "x16           38.1697      0.384     99.461      0.000      37.416      38.923\n",
       "x17           -0.0796      0.394     -0.202      0.840      -0.853       0.694\n",
       "x18            0.6095      0.373      1.633      0.103      -0.123       1.342\n",
       "x19           82.6706      0.370    223.690      0.000      81.945      83.396\n",
       "x20           -0.5558      0.382     -1.454      0.146      -1.306       0.194\n",
       "x21           69.3788      0.382    181.451      0.000      68.628      70.129\n",
       "x22           -0.2760      0.376     -0.734      0.463      -1.014       0.463\n",
       "x23           78.4182      0.385    203.868      0.000      77.663      79.173\n",
       "x24           -0.0071      0.381     -0.019      0.985      -0.755       0.740\n",
       "x25           -0.4508      0.378     -1.191      0.234      -1.194       0.292\n",
       "x26            0.0881      0.377      0.234      0.815      -0.651       0.827\n",
       "x27            5.7140      0.376     15.199      0.000       4.976       6.452\n",
       "x28           88.5939      0.381    232.561      0.000      87.846      89.342\n",
       "x29           17.3467      0.396     43.790      0.000      16.569      18.124\n",
       "x30           -0.6469      0.375     -1.726      0.085      -1.383       0.089\n",
       "==============================================================================\n",
       "Omnibus:                        3.178   Durbin-Watson:                   1.949\n",
       "Prob(Omnibus):                  0.204   Jarque-Bera (JB):                3.556\n",
       "Skew:                           0.014   Prob(JB):                        0.169\n",
       "Kurtosis:                       3.325   Cond. No.                         1.43\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.api import OLS\n",
    "\n",
    "model=OLS(y_train,x_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a8a5aa-c779-4254-a076-c9315fcf6271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 6.12524740e-02  2.19763296e-01  3.29204965e-02 -4.43866575e-01\n",
      "  3.44517668e-02  4.29964671e+01 -2.43758188e-01 -5.69542567e-01\n",
      " -6.01478506e-02 -1.05425769e-01  6.08588704e-01  6.13701047e+01\n",
      "  3.96637080e+01  4.76408991e-01 -1.93869031e-01  3.81270456e+01\n",
      " -8.08882192e-02  6.05466820e-01  8.25858726e+01 -5.48166091e-01\n",
      "  6.92560206e+01 -3.05252249e-01  7.83271386e+01 -1.69727639e-02\n",
      " -4.45334880e-01  6.99647765e-02  5.71132882e+00  8.84798413e+01\n",
      "  1.73285969e+01 -6.29589557e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model=Ridge()\n",
    "model.fit(x_train,y_train)\n",
    "print(model.alpha)\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeaf9685-f973-4c5f-a076-da49c5dfb43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 6.12524740e-02  2.19763296e-01  3.29204965e-02 -4.43866575e-01\n",
      "  3.44517668e-02  4.29964671e+01 -2.43758188e-01 -5.69542567e-01\n",
      " -6.01478506e-02 -1.05425769e-01  6.08588704e-01  6.13701047e+01\n",
      "  3.96637080e+01  4.76408991e-01 -1.93869031e-01  3.81270456e+01\n",
      " -8.08882192e-02  6.05466820e-01  8.25858726e+01 -5.48166091e-01\n",
      "  6.92560206e+01 -3.05252249e-01  7.83271386e+01 -1.69727639e-02\n",
      " -4.45334880e-01  6.99647765e-02  5.71132882e+00  8.84798413e+01\n",
      "  1.73285969e+01 -6.29589557e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "\n",
    "alpha_vals=np.arange(0.001,1,0.01)\n",
    "models=RidgeCV(alphas=alpha_vals,cv=10)\n",
    "model.fit(x_train,y_train)\n",
    "print(model.alpha)\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93b7109-1e66-464f-aeb8-ee7b1b688ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data MSE\n",
      "105.71221822459628\n",
      "Test Data MSE\n",
      "81.58838559477084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yt_pred = model.predict(x_train)\n",
    "print('Training Data MSE')\n",
    "print(mean_squared_error(y_train, yt_pred))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print('Test Data MSE')\n",
    "print(mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff06597e-d871-45b0-9a38-67410b6d1ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data MSE\n",
      "105.65678446705529\n",
      "Test Data MSE\n",
      "81.27021203872461\n",
      "Best alpha: 0.18000000000000002\n",
      "Model coefficients: [ 6.54665775e-02  2.15544099e-01  3.87182734e-02 -4.32051445e-01\n",
      "  2.81679974e-02  4.30414776e+01 -2.54812280e-01 -5.74330321e-01\n",
      " -5.66805266e-02 -1.02948063e-01  6.12510312e-01  6.14334378e+01\n",
      "  3.97220011e+01  4.80841579e-01 -1.97335299e-01  3.81567379e+01\n",
      " -8.03298750e-02  5.99620393e-01  8.26647386e+01 -5.51833234e-01\n",
      "  6.93399346e+01 -3.00507111e-01  7.84234219e+01 -2.43420519e-02\n",
      " -4.45874754e-01  7.41473745e-02  5.71852308e+00  8.85714245e+01\n",
      "  1.73455992e+01 -6.33328164e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "\n",
    "alpha_vals = np.arange(0.01, 1, 0.01)\n",
    "model = RidgeCV(alphas=alpha_vals, cv=10)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "yt_pred = model.predict(x_train)\n",
    "print('Training Data MSE')\n",
    "print(mean_squared_error(y_train, yt_pred))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print('Test Data MSE')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Best alpha:\", model.alpha_)\n",
    "print(\"Model coefficients:\", model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c855c40-5f83-4702-8009-211c0225a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data MSE\n",
      "105.65678446705529\n",
      "Test Data MSE\n",
      "81.27021203872461\n",
      "0.18000000000000002\n",
      "[ 6.54665775e-02  2.15544099e-01  3.87182734e-02 -4.32051445e-01\n",
      "  2.81679974e-02  4.30414776e+01 -2.54812280e-01 -5.74330321e-01\n",
      " -5.66805266e-02 -1.02948063e-01  6.12510312e-01  6.14334378e+01\n",
      "  3.97220011e+01  4.80841579e-01 -1.97335299e-01  3.81567379e+01\n",
      " -8.03298750e-02  5.99620393e-01  8.26647386e+01 -5.51833234e-01\n",
      "  6.93399346e+01 -3.00507111e-01  7.84234219e+01 -2.43420519e-02\n",
      " -4.45874754e-01  7.41473745e-02  5.71852308e+00  8.85714245e+01\n",
      "  1.73455992e+01 -6.33328164e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "\n",
    "alphas_vals=np.arange(0.01,1,0.01)\n",
    "models=RidgeCV(alphas=alpha_vals,cv=10)\n",
    "model.fit(x_train,y_train)\n",
    "yt_pred=model.predict(x_train)\n",
    "print('Training Data MSE')\n",
    "print(mean_squared_error(y_train,yt_pred))\n",
    "y_pred=model.predict(x_test)\n",
    "print('Test Data MSE')\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "print(model.alpha_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "342c619f-5140-4a38-a088-c9d983a9e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': np.float64(0.3509999999999999)}\n",
      "Best Score: -114.50061678769778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# Parameter grid for Ridge\n",
    "grid = {'alpha': np.arange(0.001, 1.0, 0.01)}\n",
    "\n",
    "# Correct scoring parameter\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    grid,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "results = search.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", results.best_params_)\n",
    "print(\"Best Score:\", results.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff4220b1-6a93-432e-9007-29bb77a46c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': np.float64(0.3509999999999999)}\n",
      "-114.50061678769778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np \n",
    "\n",
    "model=Ridge()\n",
    "grid={\"alpha\":np.arange(0.001,1,0.01)}\n",
    "search=GridSearchCV(model,grid,cv=10,n_jobs=-1,scoring=\"neg_mean_squared_error\")\n",
    "results=search.fit(x_train,y_train)\n",
    "print(results.best_params_)\n",
    "print(results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5df6e-fb2b-4a85-b183-438aefa1485d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
